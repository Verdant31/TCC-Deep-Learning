{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "tf.random.set_seed(221)\n",
    "np.random.seed(221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracies = []\n",
    "train_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(neurons = 32, input_shape = (15,1)):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(neurons, input_shape=input_shape))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def printMetrics(model, x, y, stage):\n",
    "  scores = model.evaluate(x, y, verbose=0)\n",
    "  print(\"(\" + stage + \")\" + \"Erro da LSTM : %.2f%%\" % (100-scores[1]*100))\n",
    "  print(\"(\" + stage + \")\" + \"Acurária da LSTM  %.2f%%\" % (scores[1]*100))\n",
    "  print(\"\\n\")\n",
    "\n",
    "  if(stage == \"TESTE\"):\n",
    "    val_accuracies.append(scores[1])\n",
    "  else:\n",
    "    train_accuracies.append(scores[1])\n",
    "\n",
    "  if(stage == \"TESTE\"):\n",
    "    print(\"Matriz de confusão (\" + stage + \")\")\n",
    "    y_pred = model.predict(x, verbose = 0)\n",
    "    y_pred = np.array(np.round(y_pred))\n",
    "    y = np.array(y)\n",
    "    cf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "    print(\"Precision, recall e f1-score\")\n",
    "    print(classification_report(y, y_pred)) \n",
    "    print(cf_matrix[0][0], \"Previu COMPRA e era COMPRA\")\n",
    "    print(cf_matrix[0][1], \"Previu COMPRA e era VENDA\")  \n",
    "    print(cf_matrix[1][0], \"Previu VENDA e era COMPRA\")\n",
    "    print(cf_matrix[1][1], \"Previu VENDA e era VENDA\")\n",
    "\n",
    "    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "def getData(action, training = False, dropDays=0):\n",
    "  step = \"treino\" if training else \"teste\"\n",
    "  df = pd.read_csv(\"./\" + action + \"./\" + step + \".csv\")\n",
    "  df.drop(columns=[\"Unnamed: 0\", \"Smoothed_Close\", \"Close\", \"Date\"], inplace=True)\n",
    "\n",
    "  if(dropDays > 0):\n",
    "    columns_to_drop = []\n",
    "    for day in reversed(range(dropDays)):\n",
    "      columns_to_drop.append(\"Past_\" + str(15-day)+ \"_Days_Close\")\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "  x = df.drop(columns=[\"Label\"])\n",
    "  y = df[\"Label\"]\n",
    "\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  x = scaler.fit_transform(x)\n",
    "  y = y.replace(-1, 0)\n",
    "  \n",
    "  x = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = \"BBAS3.SA\"\n",
    "x_train, y_train = getData(action=action, training=True)\n",
    "x_test, y_test = getData(action=action, training=False)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = buildModel()\n",
    "# history = model.fit(x_train, y_train, validation_split = 0.2, epochs=100, batch_size=10, verbose=0)\n",
    "# printMetrics(model, x_train, y_train, \"TREINO\")\n",
    "# printMetrics(model, x_test, y_test, \"TESTE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "# plt.title(\"Training vs Validation Accuracy\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend([\"train\", \"validation\"], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"BBAS3.SA\", \"CSNA3.SA\", \"PETR4.SA\", \"VALE3.SA\"]\n",
    "\n",
    "\n",
    "for action in actions:\n",
    "  x_train, y_train = getData(action=action, training=True)\n",
    "  x_test, y_test = getData(action=action, training=False)\n",
    "\n",
    "  model = buildModel()\n",
    "  print(\"Treinando modelo para a ação:\", action)\n",
    "  history = model.fit(x_train, y_train, validation_split = 0.2, epochs=100, batch_size=10, verbose=0)\n",
    "  printMetrics(model, x_train, y_train, \"TREINO\")\n",
    "  printMetrics(model, x_test, y_test, \"TESTE\")\n",
    "\n",
    "  model.save(f\"./models/lstm/{action}_model.h5\")\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"--------------------------------------------#################------------------------------------------------------\")\n",
    "  print(\"\\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando uma acuracia utilizando uma quantidade menor de t anteriores\n",
    "# Resultado: Os modelos apresentaram uma acuracia inferior ou igual a quando utilizado os 15 dias\n",
    "\n",
    "# actions = [\"BBAS3.SA\", \"CSNA3.SA\", \"PETR4.SA\", \"VALE3.SA\"]\n",
    "# for action in actions:\n",
    "#   x_train, y_train = getData(action=action, training=True, dropDays=7)\n",
    "#   x_test, y_test = getData(action=action, training=False, dropDays=7)\n",
    "\n",
    "#   model = buildModel(input_shape=(8, 1))\n",
    "#   history = model.fit(x_train, y_train, validation_split = 0.2, epochs=100, batch_size=10, verbose=0)\n",
    "#   printMetrics(model, x_train, y_train, \"TREINO\")\n",
    "  \n",
    "#   print(\"\\n\")\n",
    "#   print(\"--------------------------------------------#################------------------------------------------------------\")\n",
    "#   print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.30\n",
    "fig, ax= plt.subplots(figsize =(6, 6)) \n",
    "\n",
    "br1 = np.arange(4) \n",
    "br2 = [x + barWidth for x in br1] \n",
    " \n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.bar(br1, train_accuracies, color ='#5271FF', width = barWidth, \n",
    "        edgecolor ='grey', label ='Treino') \n",
    "plt.bar(br2, val_accuracies, color ='#FF914D', width = barWidth, \n",
    "        edgecolor ='grey', label ='Teste') \n",
    "\n",
    "plt.xticks([r + barWidth for r in range(4)], [\"BBAS3.SA\",\"CSNA3.SA\",\"PETR4.SA\",\"VALE3.SA\"])\n",
    "# plt.savefig('chart.png')\n",
    " \n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using backtest data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./backtest/BBAS3.SA.csv\")\n",
    "df.drop(columns=[\"Date\", \"Open\"], inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = df.drop(columns=[\"Close\"])\n",
    "y = df[\"Close\"]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x = scaler.fit_transform(x)\n",
    "y = y.replace(-1, 0)\n",
    "\n",
    "x = np.reshape(x, (x.shape[0], x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.saving import load_model\n",
    "loaded_model = load_model(\"./models/lstm/BBAS3.SA_model.h5\")\n",
    "y_pred = loaded_model.predict(x, verbose = 0)\n",
    "y_pred = np.array(np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./backtest/BBAS3.SA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest usando os dados do ano de 2024 (o modelo é treinado com dados de até 2023)\n",
    "quotes = 20\n",
    "balance = 0\n",
    "lucros = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  date = row.values[0] \n",
    "  day_open = float(row.values[1])\n",
    "  close = float(row.values[2])\n",
    "  \n",
    "  print(f\"Saldo atual ({date}) : {round(balance, 2)}, ação abriu em {day_open}\")\n",
    "  \n",
    "  order_text = \"Compra\" if y_pred[index] == 1 else \"Venda\"\n",
    "\n",
    "  print(f\"Saldo da ação: {round(close-day_open, 2)}\")\n",
    "  \n",
    "  if(order_text == \"Compra\" and close > day_open):\n",
    "    balance+=  abs(close - day_open) * quotes\n",
    "  if(order_text == \"Compra\" and close < day_open):\n",
    "    balance+=  -(day_open - close) * quotes\n",
    "  if(order_text == \"Venda\" and close > day_open):\n",
    "    balance+=  -(day_open - close) * quotes\n",
    "  if(order_text == \"Venda\" and close < day_open):\n",
    "    balance+=  abs(close - day_open) * quotes\n",
    "    \n",
    "  print(f\"{order_text} efetuada, dia finalizado com lucro de {round(balance,2)}, ação fechou em {close}\")\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n",
    "print(f\"Saldo final: {balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000155F4B21BD0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Saldo final: 275.59999999999997 para a ação BBAS3.SA\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000155F4B20160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Saldo final: 195.79999999999973 para a ação CSNA3.SA\n",
      "Saldo final: 378.2000000000004 para a ação PETR4.SA\n",
      "Saldo final: 237.39999999999978 para a ação VALE3.SA\n"
     ]
    }
   ],
   "source": [
    "actions = [\"BBAS3.SA\", \"CSNA3.SA\", \"PETR4.SA\", \"VALE3.SA\"]\n",
    "\n",
    "for action in actions:\n",
    "  df = pd.read_csv(f\"./backtest/{action}.csv\")\n",
    "  df.drop(columns=[\"Date\", \"Open\"], inplace=True)\n",
    "\n",
    "  x = df.drop(columns=[\"Close\"])\n",
    "  y = df[\"Close\"]\n",
    "\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  x = scaler.fit_transform(x)\n",
    "  y = y.replace(-1, 0)\n",
    "  x = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
    "\n",
    "  loaded_model = load_model(f\"./models/lstm/{action}_model.h5\")\n",
    "  y_pred = loaded_model.predict(x, verbose = 0)\n",
    "  y_pred = np.array(np.round(y_pred))\n",
    "\n",
    "  df = pd.read_csv(f\"./backtest/{action}.csv\")\n",
    "\n",
    "  quotes = 20\n",
    "  balance = 0\n",
    "  lucros = 0\n",
    "\n",
    "  for index, row in df.iterrows():\n",
    "    date = row.values[0] \n",
    "    day_open = float(row.values[1])\n",
    "    close = float(row.values[2])\n",
    "    \n",
    "    order_text = \"Compra\" if y_pred[index] == 1 else \"Venda\"\n",
    "    \n",
    "    if(order_text == \"Compra\" and close > day_open):\n",
    "      balance+=  abs(close - day_open) * quotes\n",
    "    if(order_text == \"Compra\" and close < day_open):\n",
    "      balance+=  -(day_open - close) * quotes\n",
    "    if(order_text == \"Venda\" and close > day_open):\n",
    "      balance+=  -(day_open - close) * quotes\n",
    "    if(order_text == \"Venda\" and close < day_open):\n",
    "      balance+=  abs(close - day_open) * quotes\n",
    "      \n",
    "\n",
    "  print(f\"Saldo final: {balance} para a ação {action}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
